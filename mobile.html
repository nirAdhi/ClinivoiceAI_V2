<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clinvoice Mobile Mic</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #111827;
            color: #fff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        .container { text-align: center; max-width: 400px; width: 100%; }
        h1 { font-size: 24px; margin-bottom: 10px; }
        .status { color: #9ca3af; margin-bottom: 30px; }
        
        .mic-btn {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background: #374151;
            border: none;
            cursor: pointer;
            font-size: 48px;
            margin: 20px auto;
            transition: all 0.3s;
        }
        .mic-btn.recording { background: #ef4444; animation: pulse 1s infinite; }
        .mic-btn:disabled { opacity: 0.5; cursor: not-allowed; }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        
        .timer { font-size: 48px; font-weight: 300; margin: 20px 0; }
        .info { background: #1f2937; padding: 16px; border-radius: 12px; margin-top: 20px; }
        .info p { color: #9ca3af; font-size: 14px; margin: 8px 0; }
        
        .error { background: #7f1d1d; color: #fca5a5; padding: 12px; border-radius: 8px; margin-bottom: 20px; }
        .connected { background: #065f46; color: #6ee7b7; padding: 12px; border-radius: 8px; margin-bottom: 20px; }
        
        /* Wave Animation */
        .wave-bar { 
            transition: height 0.1s ease; 
            animation-play-state: paused;
        }
        @keyframes wave {
            0%, 100% { height: 10px; }
            50% { height: 45px; }
        }
        #audioWave.recording .wave-bar { 
            animation-play-state: running; 
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ“± Clinivoice Mobile Mic</h1>
        <p class="status" id="status">Connecting to session...</p>
        
        <div id="errorBox" style="display: none;"></div>
        <div id="connectedBox" style="display: none;"></div>
        
        <div id="transcriptPreview" style="display: none; background: #1f2937; padding: 16px; border-radius: 12px; margin: 20px 0; max-height: 150px; overflow-y: auto;">
            <p style="color: #6b7280; font-size: 12px; margin-bottom: 8px;">What you're saying:</p>
            <p id="transcriptText" style="color: #fff; font-size: 16px;"></p>
        </div>
        
        <button class="mic-btn" id="micBtn" disabled>ðŸŽ¤</button>
        
        <!-- Audio Wave Visualization -->
        <div id="audioWave" style="display: none; height: 60px; margin: 20px 0; align-items: center; justify-content: center; gap: 4px;">
            <div class="wave-bar" style="width: 6px; height: 20px; background: #10b981; border-radius: 3px; animation: wave 0.5s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 30px; background: #10b981; border-radius: 3px; animation: wave 0.4s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 40px; background: #10b981; border-radius: 3px; animation: wave 0.6s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 25px; background: #10b981; border-radius: 3px; animation: wave 0.3s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 35px; background: #10b981; border-radius: 3px; animation: wave 0.5s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 20px; background: #10b981; border-radius: 3px; animation: wave 0.4s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 30px; background: #10b981; border-radius: 3px; animation: wave 0.6s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 40px; background: #10b981; border-radius: 3px; animation: wave 0.3s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 25px; background: #10b981; border-radius: 3px; animation: wave 0.5s ease-in-out infinite;"></div>
            <div class="wave-bar" style="width: 6px; height: 35px; background: #10b981; border-radius: 3px; animation: wave 0.4s ease-in-out infinite;"></div>
        </div>
        
        <div class="timer" id="timer">00:00</div>
        
        <div class="info" id="infoBox" style="display: none;">
            <p>ðŸ”´ Recording & transcribing...</p>
            <p>Speech is being converted to text in real-time</p>
        </div>
        
        <div class="info">
            <p><strong>Instructions:</strong></p>
            <p>â€¢ Tap the microphone to start</p>
            <p>â€¢ Speak clearly into your phone</p>
            <p>â€¢ Speech is transcribed in real-time</p>
            <p>â€¢ Transcription appears on your computer</p>
        </div>
    </div>

    <script>
        const urlParams = new URLSearchParams(window.location.search);
        const sessionCode = urlParams.get('code');
        const userId = urlParams.get('user') || 'user';
        
        let ws = null;
        let reconnectTimer = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let recordingTime = 0;
        let timerInterval = null;
        let recognition = null;
        let finalTranscript = '';
        let isAuthenticated = false;
        
        const statusEl = document.getElementById('status');
        const micBtn = document.getElementById('micBtn');
        const timerEl = document.getElementById('timer');
        const infoBox = document.getElementById('infoBox');
        const errorBox = document.getElementById('errorBox');
        const connectedBox = document.getElementById('connectedBox');
        
        if (!sessionCode) {
            statusEl.textContent = 'No session code found';
            errorBox.style.display = 'block';
            errorBox.textContent = 'Please scan the QR code from your computer to start a session';
            errorBox.className = 'error';
        } else {
            statusEl.textContent = `Session: ${sessionCode}`;
            connectWebSocket();
        }
        
        function connectWebSocket() {
            const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsUrl = `${protocol}//${window.location.host}?sessionCode=${sessionCode}&userId=${userId}&type=mobile`;
            console.log('Connecting to:', wsUrl);
            console.log('Location host:', window.location.host);
            console.log('Location protocol:', window.location.protocol);
            
            statusEl.textContent = 'Connecting to server...';
            
            ws = new WebSocket(wsUrl);
            
            ws.onopen = () => {
                console.log('WebSocket connected, sending auth...');
                statusEl.textContent = 'Authenticating...';
                // Send auth message to verify session
                ws.send(JSON.stringify({ 
                    type: 'auth', 
                    sessionCode: sessionCode 
                }));
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                statusEl.textContent = 'Connection error';
            };
            
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                console.log('WS message:', data.type);
                
                if (data.type === 'authenticated') {
                    isAuthenticated = true;
                    statusEl.textContent = 'Ready to record - tap mic to start';
                    connectedBox.style.display = 'block';
                    connectedBox.textContent = 'âœ“ Connected to computer';
                    connectedBox.className = 'connected';
                    micBtn.disabled = false;
                } else if (data.type === 'error') {
                    showError(data.message);
                } else if (data.type === 'session_closed') {
                    isAuthenticated = false;
                    showError('Session closed by computer');
                    stopRecording();
                } else if (data.type === 'web_disconnected') {
                    // Computer still there, just not listening
                    connectedBox.textContent = 'âœ“ Connected (waiting for computer)';
                }
            };
            
            ws.onclose = (event) => {
                console.log('WebSocket closed:', event.code, event.reason);
                connectedBox.style.display = 'none';
                micBtn.disabled = true;
                
                if (isAuthenticated && event.code === 1000) {
                    // Intentionally closed
                    statusEl.textContent = 'Disconnected';
                } else if (isAuthenticated) {
                    // Was connected, try to reconnect
                    statusEl.textContent = 'Reconnecting...';
                    setTimeout(connectWebSocket, 3000);
                }
                stopRecording();
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                statusEl.textContent = 'Connection error';
            };
        }
        
        function showError(msg) {
            errorBox.style.display = 'block';
            errorBox.textContent = msg;
            errorBox.className = 'error';
        }
        
        micBtn.addEventListener('click', async () => {
            if (isRecording) {
                stopRecording();
            } else {
                await startRecording();
            }
        });
        
        async function startRecording() {
            // Use Web Speech API for real-time transcription
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                showError('Speech recognition not supported on this device');
                return;
            }
            
            // Stop any existing recognition
            if (recognition) {
                try { recognition.stop(); } catch(e) {}
            }
            
            recognition = new SpeechRecognition();
            recognition.continuous = false; // Don't auto-restart
            recognition.interimResults = false; // Only get final results to avoid duplicates
            recognition.lang = 'en-US';
            
            recognition.onresult = (event) => {
                for (let i = 0; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript.trim();
                    console.log('Final transcript:', transcript);
                    
                    if (transcript && event.results[i].isFinal) {
                        // Show preview
                        document.getElementById('transcriptPreview').style.display = 'block';
                        document.getElementById('transcriptText').textContent = transcript;
                        
                        // Send to server
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            ws.send(JSON.stringify({
                                type: 'transcript',
                                transcript: transcript,
                                isFinal: true
                            }));
                        }
                    }
                }
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'not-allowed') {
                    showError('Microphone access denied');
                } else if (event.error === 'no-speech') {
                    // Ignore no-speech, just restart quietly
                    if (isRecording && recognition) {
                        try { recognition.start(); } catch(e) {}
                    }
                } else if (event.error !== 'aborted' && isRecording) {
                    // Restart on error after delay
                    setTimeout(() => {
                        if (isRecording && recognition) {
                            try { recognition.start(); } catch(e) {}
                        }
                    }, 500);
                }
            };
            
            recognition.onend = () => {
                // Only restart if still recording - wait longer to reduce beeping
                if (isRecording && recognition) {
                    setTimeout(() => {
                        if (isRecording && recognition) {
                            try { recognition.start(); } catch(e) {}
                        }
                    }, 1000); // 1 second delay to reduce beeping
                }
            };
            
            try {
                recognition.start();
            } catch(e) {
                console.log('Recognition start error:', e);
            }
            
            // Notify server that recording started
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'mobile_recording_started' }));
            }
            
            isRecording = true;
            micBtn.classList.add('recording');
            micBtn.textContent = 'â¹ï¸';
            infoBox.style.display = 'block';
            const audioWave = document.getElementById('audioWave');
            audioWave.style.display = 'flex';
            audioWave.classList.add('recording');
            statusEl.textContent = 'Recording & transcribing...';
            
            // Start timer
            recordingTime = 0;
            timerInterval = setInterval(() => {
                recordingTime++;
                const mins = Math.floor(recordingTime / 60);
                const secs = recordingTime % 60;
                timerEl.textContent = `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
            }, 1000);
        }
        
        function stopRecording() {
            if (recognition) {
                recognition.stop();
                recognition = null;
            }
            
            isRecording = false;
            micBtn.classList.remove('recording');
            micBtn.textContent = 'ðŸŽ¤';
            infoBox.style.display = 'none';
            const audioWave = document.getElementById('audioWave');
            audioWave.style.display = 'none';
            audioWave.classList.remove('recording');
            document.getElementById('transcriptPreview').style.display = 'none';
            statusEl.textContent = 'Recording stopped';
            finalTranscript = '';
            
            if (timerInterval) {
                clearInterval(timerInterval);
                timerInterval = null;
            }
            
            // Send stop and recording stopped signals
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'mobile_recording_stopped' }));
                ws.send(JSON.stringify({ type: 'stop' }));
            }
        }
    </script>
</body>
</html>
